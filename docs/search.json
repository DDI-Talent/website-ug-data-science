[
  {
    "objectID": "content/week-4/topic-3.html",
    "href": "content/week-4/topic-3.html",
    "title": "Roundup and recap",
    "section": "",
    "text": "At the beginning of this course we introduced R by highlighting one of its main attractions: reproducibility. And here we are at the end of the course still banging on about reproducibility, but that’s because it is so important.\nThere is a growing awareness of the importance of reproducibility in data processing and analysis, and thankfully the tools needed to generate reproducible outputs are more accessible than ever before, helping to make this easier to accomplish.\nThere are many ways in which you can ensure your work is reproducible. The first we would recommend, is to start using R, and the second is to become familiar with R Markdown, so you are well on your way!  \nHere is a reminder of some of the main points to bear in mind, to ensure your future self and others can easily and efficiently build on the analysis you have carried out in R:\n\nalways create an RStudio Project to work in\nuse raw data directly in R (no pre-editing with other software)\ninclude informative commenting\nensure code is easy to read with appropriate indentations and spacing\npipe  %&gt;%  with the Tidyverse\ngive your objects meaningful names\nwork in R Markdown for reporting\n\nLet’s look at these aspects in little more detail.\n\nBy now you should be familiar with the how and the why of creating Projects in RStudio as this has cropped up frequently throughout the course. Projects help to keep everything in one place, they help R to find all your files and folders easily, and they generally make your life a lot easier so you should definitely be using them. \n Always use the raw data. If your data has come from a database or from a publicly updated data source, avoid the temptation of doing some quick and dirty data wrangling in Excel before importing into R. This would make your analysis less reproducible as you may not always remember exactly what steps you took during this initial phase and these steps would then need to be taken each time you wanted to repeat or carry out a similar operation. \n\nCode which is easy to decipher and understand can be revisited in the future and rerun more easily, but how many times have you looked back at scribbled notes you took in haste, or code you typed quickly, with no recollection of what it all means? By including informative commenting you can help your future self, or anyone else who might be looking at your code, understand what it is you were trying to do at each point in your script. It isn’t needed for all lines of code but should be used when there might be ambiguity, or to provide clarification, or remind yourself about something specific to do with what’s happening. The keyboard shortcut for commenting/uncommenting a line is Ctrl+Shift+C, or you can manually type  # .\neasyread.svg\nOn a similar theme, it is important to make your code easy to read by applying the appropriate indentations and spacing. The keyboard shortcut for quickly reformatting your code is Ctrl+I (first select your code, or use Ctrl+A to select all before doing Ctrl+I). If your script is long this is particularly important as it means you, or someone else, can scan the document more easily to find the relevant text or information. \n\n\nThe Tidyverse has featured heavily in this course and is another great way to make your code easier to read and understand due to the use of the  %&gt;%  operator. As we learned at the beginning of the course, the  %&gt;% reduces the need for nested functions, where each function is “nested” inside another making it potentially very difficult to debug. Instead the piped (  %&gt;% ) functions appear almost like a series of statements or instructions, which can be run line by line if needed. At the start of every R script or document, remember to include  library(tidyverse) .\n\nTo finish, just a final note about assigning your objects meaningful names. This is easily overlooked and can be surprisingly difficult but when given careful consideration, good object naming can make your life a lot easier, and again, make the code easier to understand and read. Avoid generic names such as data or plot as these can cause problems. This is particularly true if you are carrying out multiple analyses and have referred to “data” or “plot” somewhere else and not cleared your environment (Restart R often!). Also, when choosing names, no spaces or funky characters, stick to lowercase with underscores. Then be consistent, and you should be safe! \n\nR Markdown is one of the keys to producing reproducible analysis in R as it enables the code and the narrative to be easily combined, whilst providing great flexibility as to how the output might be displayed. It is certainly worth the effort becoming familiar with R Markdown which was covered in detail in Week 6: Topics 1 & 2. Creating a new R Markdown document is as simple as going to  File - New File - R Markdown - OK  then delete everything up to the first code chunk (it is useful to leave the first setup chunk) and you are ready to go!\n\n\nR Markdown is not only a powerful tool for ensuring reproducibility, but as you have already discovered, it includes many features which make it easy to create and share clear and professional looking documents for a wide range of audiences.\nHere are some things to remember when planning and designing a report with R Markdown:\n\nprovide a clear structure using Markdown section headers (#, ##, ###)\nbe conscious of the YAML, unlike R code, the YAML is very sensitive of extra spaces/formatting\nconsider the code output options depending on audience (`echo = TRUE` vs `echo = FALSE`)\nthink about the story you are trying to tell\nmake good use of figures\nuse tables appropriately\n\n\nIt is important to provide a clear structure in any report or document you are writing and R Markdown makes it easy to manage and display the structure through the use of headers. The hash symbol ( # ) is used in the Markdown sections (all the bits which aren’t code chunks or YAML) to indicate different levels of header, so how big or small the text should be. These headers also show up in the document outline which is extremely useful as a means of navigating your document when editing, helping to save you time.  \nThe structure of your R code chunks is important too. For example, it is good practice to have a code chunk near the top of your document (often in the setup chunk) where you keep all the packages that you are using together. It might look something like the image on the right.  The next code chunk is often where you might choose to load your data and is likely to include the code similar to:  mydata &lt;- read_csv(here(“data”, “appointments.csv”)) \n\nWe’ve already mentioned that Markdown headers ( # ) make it easy to define a clear structure in your R Markdown document. Explore some of the other Markdown features, such as **bold** and *italic* or `inline R code`, which can help to give your final document a high quality finish. Remember, you can access the Markdown Quick Reference guide from the Help menu.\nIn its most basic form, the YAML which appears at the top of your R Markdown document, could simply tell R Markdown what output format you would like your document to be in, in which case it would look like this, indicating HTML output:\n---\noutput: html_document\n---\n\nHowever, you have the potential to add many attractive features via the YAML, such as table of contents, section numbering, themes, and much more. You have to be particularly careful about indentation in the YAML (unlike in R code chunks where indentation is mainly for readability) but you can start exploring YAML options easily through changing settings in the document cog and this will automatically update your YAML.\nDepending on who your intended audience is, you have a number of output options available to you. You can choose whether or not to show or run your code in the final document. Showing you code in the Markdown output document (HTML, Word, PDF) is denoted `echo = TRUE`, not showing it is denoted `echo = FALSE`. You also have control over whether to display the output of each code chunk or not too. These options can be accessed from the individual code chunk cogs or can be set for the whole document in the setup chunk.\n\nWhen creating a report or document, think about what story you are trying to tell with the data; you might be answering a specific question or perhaps highlighting a change in activity over a period of time. R Markdown makes it easy to intersperse clear and informative visual elements throughout the narrative. These could be in the form of figures and plots, nicely formatted tables or even images (e.g. JPG or PNG).\nWhen writing the code to produce a plot, remember you don’t need to assign it to an object. For example, running  myplot &lt;- mydata %&gt;% ggplot()  will result in no plot appearing in your final document, it is saved in the Environment. Instead you can simply write  mydata %&gt;% ggplot() which will ensure your plot does appear. You can also control the size of your plots and figures in the code chunk settings cog.\nWhen writing the code for a table which you want to include in your final document, remember that the function  kable()  in the knitr package helps provide consistent table formatting across various different outputs. Also note that the same principles apply concerning whether or not your table output will appear as those referred to in plotting; no need to save the table first, you can simply write  mydata %&gt;% kable() .\nAnd finally, as addictive as it is creating beautiful plots with ggplot2, try not to bombard the reader with too many tables and figures. Choose wisely the information you would like to display in order to tell your story concisely and make good use of ggplot2’s ability to provide a breadth of information in one plot, through careful use of aesthetic mappings. \n\n\n\nIn this course we have covered a whole variety of functions which you will find useful when carrying out data wrangling, plotting and analysis in R. There are however some functions which you will find yourself using more frequently than others and in the following sections we provide a quick recap on some of these more common functions.\nThe examples below are intended as a quick reference guide to remind yourself which functions to use in which settings. They can be copied and pasted straight into an R Markdown document as code chunk to test, but if you are copying multiple code chunks, you only need to include the packages once.\nNote: The examples below all use the gapminder dataset which is loaded by running the command  library(gapminder) . In your own projects you would load your data with the command read_csv(“mydata.csv”)  or similar, depending on the format and location of your data.\n\n\ndistinct() returns only distinct (unique) rows in a data frame\nIn the example below we have included the variable  continent  so that we can explore how many unique categories there are in this column.\n\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.3\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nWarning: package 'tibble' was built under R version 4.2.3\n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'purrr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\nWarning: package 'forcats' was built under R version 4.2.3\n\n\nWarning: package 'lubridate' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.1     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gapminder)\ngapminder %&gt;%\n  distinct(continent)\n\n# A tibble: 5 × 1\n  continent\n  &lt;fct&gt;    \n1 Asia     \n2 Europe   \n3 Africa   \n4 Americas \n5 Oceania  \n\n\nUseful for:\n\nexploring categories\nspotting spelling mistakes\nlooking at date ranges\nremoving duplicate rows\nTry this out: \n\n\ngapminder %&gt;%\ncount(contintent)\nfilter()  returns a subset of rows based on a condition\nIn the example below we have specified that we only want to see results where  country  is equal to  Ghana .\n\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\n  filter(country == \"Ghana\")\n\n# A tibble: 12 × 6\n   country continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;   &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Ghana   Africa     1952    43.1  5581001      911.\n 2 Ghana   Africa     1957    44.8  6391288     1044.\n 3 Ghana   Africa     1962    46.5  7355248     1190.\n 4 Ghana   Africa     1967    48.1  8490213     1126.\n 5 Ghana   Africa     1972    49.9  9354120     1178.\n 6 Ghana   Africa     1977    51.8 10538093      993.\n 7 Ghana   Africa     1982    53.7 11400338      876.\n 8 Ghana   Africa     1987    55.7 14168101      847.\n 9 Ghana   Africa     1992    57.5 16278738      925.\n10 Ghana   Africa     1997    58.6 18418288     1005.\n11 Ghana   Africa     2002    58.5 20550751     1112.\n12 Ghana   Africa     2007    60.0 22873338     1328.\n\n\nUseful for:\n\nfiltering your data to remove unwanted rows\nfiltering your data as part of the exploratory phase\nfiltering your data prior to piping into  ggplot() \n\nRemember:\n\nthe “equal to” comparison operator needs double  == \nto use inverted commas (““) for non-numbers \n\n\n\n\nselect() lets you choose which columns to select\nIn the example below we have chosen to select only 4 variables from our dataset and we have also changed the order in which they appear.\n\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\n  select(country, year, pop, lifeExp)\n\n# A tibble: 1,704 × 4\n   country      year      pop lifeExp\n   &lt;fct&gt;       &lt;int&gt;    &lt;int&gt;   &lt;dbl&gt;\n 1 Afghanistan  1952  8425333    28.8\n 2 Afghanistan  1957  9240934    30.3\n 3 Afghanistan  1962 10267083    32.0\n 4 Afghanistan  1967 11537966    34.0\n 5 Afghanistan  1972 13079460    36.1\n 6 Afghanistan  1977 14880372    38.4\n 7 Afghanistan  1982 12881816    39.9\n 8 Afghanistan  1987 13867957    40.8\n 9 Afghanistan  1992 16317921    41.7\n10 Afghanistan  1997 22227415    41.8\n# ℹ 1,694 more rows\n\n\nUseful for:\n\nremoving unwanted columns (e.g. columns with NAs, or things you’re just not going to use)\nfocusing on selected columns for further exploration\nre-ordering columns for ease of viewing\nselect() can also be used to rename columns, e.g.\n\n\ngapminder %&gt;% \n  select(country, year, population = pop, life_expectancy = lifeExp)\n\nAnd select() has a sister function called rename(), that can be used to rename columns without removing the ones you don’t list, e.g.:\n\n\ngapminder %&gt;%\n  rename(population = pop, life_expectancy = lifeExp)\n\n\n\nmutate() allows you to add a column or update an existing column\nIn the example below we have created a new column called  pop_millions  so that we can display the population as a decimal number of millions.\n\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\n  mutate(pop_millions = pop/1000000)\n\n# A tibble: 1,704 × 7\n   country     continent  year lifeExp      pop gdpPercap pop_millions\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.         8.43\n 2 Afghanistan Asia       1957    30.3  9240934      821.         9.24\n 3 Afghanistan Asia       1962    32.0 10267083      853.        10.3 \n 4 Afghanistan Asia       1967    34.0 11537966      836.        11.5 \n 5 Afghanistan Asia       1972    36.1 13079460      740.        13.1 \n 6 Afghanistan Asia       1977    38.4 14880372      786.        14.9 \n 7 Afghanistan Asia       1982    39.9 12881816      978.        12.9 \n 8 Afghanistan Asia       1987    40.8 13867957      852.        13.9 \n 9 Afghanistan Asia       1992    41.7 16317921      649.        16.3 \n10 Afghanistan Asia       1997    41.8 22227415      635.        22.2 \n# ℹ 1,694 more rows\n\n\nUseful for:\n\nadding an extra column containing a calculation\ncombining with group_by()  for grouped calculations\nupdating a column which has mistakes\nconverting a column to a different data type\n\nRemember:\n\nyour new column is always added at the end of your tibble (data frame)\nthe value to the left of the =  is the new name for you column and could be called anything\nif you want to replace a column, the value to the left of the =  must be exactly the same name as the column to replace\n\n\n\n\nsummarise() returns a new tibble (data frame) containing summary statistics based on what has been specified in the function.\nIn the example below the summarise function has calculated the average life expectancy for the whole gapminder dataset by averaging all observations (or rows). On its own,  summarise()  is not so useful, but when combined with group_by()  its use becomes apparent, see later examples.\n\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\n  summarise(avg_life_exp = mean(lifeExp))\n\n# A tibble: 1 × 1\n  avg_life_exp\n         &lt;dbl&gt;\n1         59.5\n\n\nUseful for:\n\ncombining with group_by()  to perform grouped calculations\n\n\n\n\ngroup_by() lets you choose how you want the variables in your dataset to be grouped so that you can perform operations (such as sum() or mean()) on these groups.\nIn the example below we have grouped our data by the variable year. Notice that the output to this chunk of code looks no different to how it would look if we just ran  gapminderwithout any grouping. This is because the effects of group_by()  are only noticeable when we start performing operations.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\n  group_by(year)\n\n# A tibble: 1,704 × 6\n# Groups:   year [12]\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 1,694 more rows\n\n\nIn this next example we have combined group_by() with the summarise() command and now, instead of seeing an average life expectancy for the whole tibble (as in the example above), we see that life expectancy has been averaged within each year group.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\ngroup_by(year) %&gt;%\n  summarise(avg_life_exp = mean(lifeExp))\n\n# A tibble: 12 × 2\n    year avg_life_exp\n   &lt;int&gt;        &lt;dbl&gt;\n 1  1952         49.1\n 2  1957         51.5\n 3  1962         53.6\n 4  1967         55.7\n 5  1972         57.6\n 6  1977         59.6\n 7  1982         61.5\n 8  1987         63.2\n 9  1992         64.2\n10  1997         65.0\n11  2002         65.7\n12  2007         67.0\n\n\nUseful for:\n\ncombining with summarise()or mutate() for grouped calculations\npreparing summary statistics for plotting\nexploring values within groups in your data\n\nRemember:\n\nto use  ungroup()  if carrying out further data manipulations to avoid unexpected results, as by default, mutate() and summarise() silently retain the groupings.\nthe value to the left of the  =  is the new name for your column and could be called anything\n\nleft_join()  allows you to combine two datasets\nIn the example below we are joining the gapminder tibble to another tibble we can access directly from the gapminder package, the  country_codes data frame, in order to add the ISO country codes.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\n  left_join(country_codes)\n\nJoining with `by = join_by(country)`\n\n\n# A tibble: 1,704 × 8\n   country     continent  year lifeExp      pop gdpPercap iso_alpha iso_num\n   &lt;chr&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;int&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779. AFG             4\n 2 Afghanistan Asia       1957    30.3  9240934      821. AFG             4\n 3 Afghanistan Asia       1962    32.0 10267083      853. AFG             4\n 4 Afghanistan Asia       1967    34.0 11537966      836. AFG             4\n 5 Afghanistan Asia       1972    36.1 13079460      740. AFG             4\n 6 Afghanistan Asia       1977    38.4 14880372      786. AFG             4\n 7 Afghanistan Asia       1982    39.9 12881816      978. AFG             4\n 8 Afghanistan Asia       1987    40.8 13867957      852. AFG             4\n 9 Afghanistan Asia       1992    41.7 16317921      649. AFG             4\n10 Afghanistan Asia       1997    41.8 22227415      635. AFG             4\n# ℹ 1,694 more rows\n\n\nUseful for:\n\ncombining two sets of data which share an id (e.g. patient id, appointment id)\nadding in information from a lookup table (e.g. country codes, Health Board names)\n\nRemember:\n\nto watch out what happens to missing values\nto keep an eye on the number of observations in each tibble before and after joining\nto check which columns are being joined by\n\nOther functions for wrangling data and what they might be useful for:\n\n arrange()  for sorting the values within a column\n desc() for indicating descending sort order when used within arrange()\n str_replace()  for updating spelling mistakes in a column\n paste()  for joining things together and adding new text \n ymd()  for reading in dates in strange formats\n factor()  for converting a variable to factor data type\n fct_relevel()  for changing the order of factors\n pivot_longer()  for reshaping your data if you have values in column headings\n pivot_wider()  for reshaping your data if you have multiple variables in one column",
    "crumbs": [
      "Content",
      "Week 4: Analysing and Presenting Data in R",
      "Topic 3: Roundup and recap"
    ]
  },
  {
    "objectID": "content/week-4/topic-3.html#reproducibility-in-r",
    "href": "content/week-4/topic-3.html#reproducibility-in-r",
    "title": "Roundup and recap",
    "section": "",
    "text": "At the beginning of this course we introduced R by highlighting one of its main attractions: reproducibility. And here we are at the end of the course still banging on about reproducibility, but that’s because it is so important.\nThere is a growing awareness of the importance of reproducibility in data processing and analysis, and thankfully the tools needed to generate reproducible outputs are more accessible than ever before, helping to make this easier to accomplish.\nThere are many ways in which you can ensure your work is reproducible. The first we would recommend, is to start using R, and the second is to become familiar with R Markdown, so you are well on your way!  \nHere is a reminder of some of the main points to bear in mind, to ensure your future self and others can easily and efficiently build on the analysis you have carried out in R:\n\nalways create an RStudio Project to work in\nuse raw data directly in R (no pre-editing with other software)\ninclude informative commenting\nensure code is easy to read with appropriate indentations and spacing\npipe  %&gt;%  with the Tidyverse\ngive your objects meaningful names\nwork in R Markdown for reporting\n\nLet’s look at these aspects in little more detail.\n\nBy now you should be familiar with the how and the why of creating Projects in RStudio as this has cropped up frequently throughout the course. Projects help to keep everything in one place, they help R to find all your files and folders easily, and they generally make your life a lot easier so you should definitely be using them. \n Always use the raw data. If your data has come from a database or from a publicly updated data source, avoid the temptation of doing some quick and dirty data wrangling in Excel before importing into R. This would make your analysis less reproducible as you may not always remember exactly what steps you took during this initial phase and these steps would then need to be taken each time you wanted to repeat or carry out a similar operation. \n\nCode which is easy to decipher and understand can be revisited in the future and rerun more easily, but how many times have you looked back at scribbled notes you took in haste, or code you typed quickly, with no recollection of what it all means? By including informative commenting you can help your future self, or anyone else who might be looking at your code, understand what it is you were trying to do at each point in your script. It isn’t needed for all lines of code but should be used when there might be ambiguity, or to provide clarification, or remind yourself about something specific to do with what’s happening. The keyboard shortcut for commenting/uncommenting a line is Ctrl+Shift+C, or you can manually type  # .\neasyread.svg\nOn a similar theme, it is important to make your code easy to read by applying the appropriate indentations and spacing. The keyboard shortcut for quickly reformatting your code is Ctrl+I (first select your code, or use Ctrl+A to select all before doing Ctrl+I). If your script is long this is particularly important as it means you, or someone else, can scan the document more easily to find the relevant text or information. \n\n\nThe Tidyverse has featured heavily in this course and is another great way to make your code easier to read and understand due to the use of the  %&gt;%  operator. As we learned at the beginning of the course, the  %&gt;% reduces the need for nested functions, where each function is “nested” inside another making it potentially very difficult to debug. Instead the piped (  %&gt;% ) functions appear almost like a series of statements or instructions, which can be run line by line if needed. At the start of every R script or document, remember to include  library(tidyverse) .\n\nTo finish, just a final note about assigning your objects meaningful names. This is easily overlooked and can be surprisingly difficult but when given careful consideration, good object naming can make your life a lot easier, and again, make the code easier to understand and read. Avoid generic names such as data or plot as these can cause problems. This is particularly true if you are carrying out multiple analyses and have referred to “data” or “plot” somewhere else and not cleared your environment (Restart R often!). Also, when choosing names, no spaces or funky characters, stick to lowercase with underscores. Then be consistent, and you should be safe! \n\nR Markdown is one of the keys to producing reproducible analysis in R as it enables the code and the narrative to be easily combined, whilst providing great flexibility as to how the output might be displayed. It is certainly worth the effort becoming familiar with R Markdown which was covered in detail in Week 6: Topics 1 & 2. Creating a new R Markdown document is as simple as going to  File - New File - R Markdown - OK  then delete everything up to the first code chunk (it is useful to leave the first setup chunk) and you are ready to go!\n\n\nR Markdown is not only a powerful tool for ensuring reproducibility, but as you have already discovered, it includes many features which make it easy to create and share clear and professional looking documents for a wide range of audiences.\nHere are some things to remember when planning and designing a report with R Markdown:\n\nprovide a clear structure using Markdown section headers (#, ##, ###)\nbe conscious of the YAML, unlike R code, the YAML is very sensitive of extra spaces/formatting\nconsider the code output options depending on audience (`echo = TRUE` vs `echo = FALSE`)\nthink about the story you are trying to tell\nmake good use of figures\nuse tables appropriately\n\n\nIt is important to provide a clear structure in any report or document you are writing and R Markdown makes it easy to manage and display the structure through the use of headers. The hash symbol ( # ) is used in the Markdown sections (all the bits which aren’t code chunks or YAML) to indicate different levels of header, so how big or small the text should be. These headers also show up in the document outline which is extremely useful as a means of navigating your document when editing, helping to save you time.  \nThe structure of your R code chunks is important too. For example, it is good practice to have a code chunk near the top of your document (often in the setup chunk) where you keep all the packages that you are using together. It might look something like the image on the right.  The next code chunk is often where you might choose to load your data and is likely to include the code similar to:  mydata &lt;- read_csv(here(“data”, “appointments.csv”)) \n\nWe’ve already mentioned that Markdown headers ( # ) make it easy to define a clear structure in your R Markdown document. Explore some of the other Markdown features, such as **bold** and *italic* or `inline R code`, which can help to give your final document a high quality finish. Remember, you can access the Markdown Quick Reference guide from the Help menu.\nIn its most basic form, the YAML which appears at the top of your R Markdown document, could simply tell R Markdown what output format you would like your document to be in, in which case it would look like this, indicating HTML output:\n---\noutput: html_document\n---\n\nHowever, you have the potential to add many attractive features via the YAML, such as table of contents, section numbering, themes, and much more. You have to be particularly careful about indentation in the YAML (unlike in R code chunks where indentation is mainly for readability) but you can start exploring YAML options easily through changing settings in the document cog and this will automatically update your YAML.\nDepending on who your intended audience is, you have a number of output options available to you. You can choose whether or not to show or run your code in the final document. Showing you code in the Markdown output document (HTML, Word, PDF) is denoted `echo = TRUE`, not showing it is denoted `echo = FALSE`. You also have control over whether to display the output of each code chunk or not too. These options can be accessed from the individual code chunk cogs or can be set for the whole document in the setup chunk.\n\nWhen creating a report or document, think about what story you are trying to tell with the data; you might be answering a specific question or perhaps highlighting a change in activity over a period of time. R Markdown makes it easy to intersperse clear and informative visual elements throughout the narrative. These could be in the form of figures and plots, nicely formatted tables or even images (e.g. JPG or PNG).\nWhen writing the code to produce a plot, remember you don’t need to assign it to an object. For example, running  myplot &lt;- mydata %&gt;% ggplot()  will result in no plot appearing in your final document, it is saved in the Environment. Instead you can simply write  mydata %&gt;% ggplot() which will ensure your plot does appear. You can also control the size of your plots and figures in the code chunk settings cog.\nWhen writing the code for a table which you want to include in your final document, remember that the function  kable()  in the knitr package helps provide consistent table formatting across various different outputs. Also note that the same principles apply concerning whether or not your table output will appear as those referred to in plotting; no need to save the table first, you can simply write  mydata %&gt;% kable() .\nAnd finally, as addictive as it is creating beautiful plots with ggplot2, try not to bombard the reader with too many tables and figures. Choose wisely the information you would like to display in order to tell your story concisely and make good use of ggplot2’s ability to provide a breadth of information in one plot, through careful use of aesthetic mappings. \n\n\n\nIn this course we have covered a whole variety of functions which you will find useful when carrying out data wrangling, plotting and analysis in R. There are however some functions which you will find yourself using more frequently than others and in the following sections we provide a quick recap on some of these more common functions.\nThe examples below are intended as a quick reference guide to remind yourself which functions to use in which settings. They can be copied and pasted straight into an R Markdown document as code chunk to test, but if you are copying multiple code chunks, you only need to include the packages once.\nNote: The examples below all use the gapminder dataset which is loaded by running the command  library(gapminder) . In your own projects you would load your data with the command read_csv(“mydata.csv”)  or similar, depending on the format and location of your data.\n\n\ndistinct() returns only distinct (unique) rows in a data frame\nIn the example below we have included the variable  continent  so that we can explore how many unique categories there are in this column.\n\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.3\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nWarning: package 'tibble' was built under R version 4.2.3\n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'purrr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\nWarning: package 'forcats' was built under R version 4.2.3\n\n\nWarning: package 'lubridate' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.1     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gapminder)\ngapminder %&gt;%\n  distinct(continent)\n\n# A tibble: 5 × 1\n  continent\n  &lt;fct&gt;    \n1 Asia     \n2 Europe   \n3 Africa   \n4 Americas \n5 Oceania  \n\n\nUseful for:\n\nexploring categories\nspotting spelling mistakes\nlooking at date ranges\nremoving duplicate rows\nTry this out: \n\n\ngapminder %&gt;%\ncount(contintent)\nfilter()  returns a subset of rows based on a condition\nIn the example below we have specified that we only want to see results where  country  is equal to  Ghana .\n\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\n  filter(country == \"Ghana\")\n\n# A tibble: 12 × 6\n   country continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;   &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Ghana   Africa     1952    43.1  5581001      911.\n 2 Ghana   Africa     1957    44.8  6391288     1044.\n 3 Ghana   Africa     1962    46.5  7355248     1190.\n 4 Ghana   Africa     1967    48.1  8490213     1126.\n 5 Ghana   Africa     1972    49.9  9354120     1178.\n 6 Ghana   Africa     1977    51.8 10538093      993.\n 7 Ghana   Africa     1982    53.7 11400338      876.\n 8 Ghana   Africa     1987    55.7 14168101      847.\n 9 Ghana   Africa     1992    57.5 16278738      925.\n10 Ghana   Africa     1997    58.6 18418288     1005.\n11 Ghana   Africa     2002    58.5 20550751     1112.\n12 Ghana   Africa     2007    60.0 22873338     1328.\n\n\nUseful for:\n\nfiltering your data to remove unwanted rows\nfiltering your data as part of the exploratory phase\nfiltering your data prior to piping into  ggplot() \n\nRemember:\n\nthe “equal to” comparison operator needs double  == \nto use inverted commas (““) for non-numbers \n\n\n\n\nselect() lets you choose which columns to select\nIn the example below we have chosen to select only 4 variables from our dataset and we have also changed the order in which they appear.\n\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\n  select(country, year, pop, lifeExp)\n\n# A tibble: 1,704 × 4\n   country      year      pop lifeExp\n   &lt;fct&gt;       &lt;int&gt;    &lt;int&gt;   &lt;dbl&gt;\n 1 Afghanistan  1952  8425333    28.8\n 2 Afghanistan  1957  9240934    30.3\n 3 Afghanistan  1962 10267083    32.0\n 4 Afghanistan  1967 11537966    34.0\n 5 Afghanistan  1972 13079460    36.1\n 6 Afghanistan  1977 14880372    38.4\n 7 Afghanistan  1982 12881816    39.9\n 8 Afghanistan  1987 13867957    40.8\n 9 Afghanistan  1992 16317921    41.7\n10 Afghanistan  1997 22227415    41.8\n# ℹ 1,694 more rows\n\n\nUseful for:\n\nremoving unwanted columns (e.g. columns with NAs, or things you’re just not going to use)\nfocusing on selected columns for further exploration\nre-ordering columns for ease of viewing\nselect() can also be used to rename columns, e.g.\n\n\ngapminder %&gt;% \n  select(country, year, population = pop, life_expectancy = lifeExp)\n\nAnd select() has a sister function called rename(), that can be used to rename columns without removing the ones you don’t list, e.g.:\n\n\ngapminder %&gt;%\n  rename(population = pop, life_expectancy = lifeExp)\n\n\n\nmutate() allows you to add a column or update an existing column\nIn the example below we have created a new column called  pop_millions  so that we can display the population as a decimal number of millions.\n\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\n  mutate(pop_millions = pop/1000000)\n\n# A tibble: 1,704 × 7\n   country     continent  year lifeExp      pop gdpPercap pop_millions\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.         8.43\n 2 Afghanistan Asia       1957    30.3  9240934      821.         9.24\n 3 Afghanistan Asia       1962    32.0 10267083      853.        10.3 \n 4 Afghanistan Asia       1967    34.0 11537966      836.        11.5 \n 5 Afghanistan Asia       1972    36.1 13079460      740.        13.1 \n 6 Afghanistan Asia       1977    38.4 14880372      786.        14.9 \n 7 Afghanistan Asia       1982    39.9 12881816      978.        12.9 \n 8 Afghanistan Asia       1987    40.8 13867957      852.        13.9 \n 9 Afghanistan Asia       1992    41.7 16317921      649.        16.3 \n10 Afghanistan Asia       1997    41.8 22227415      635.        22.2 \n# ℹ 1,694 more rows\n\n\nUseful for:\n\nadding an extra column containing a calculation\ncombining with group_by()  for grouped calculations\nupdating a column which has mistakes\nconverting a column to a different data type\n\nRemember:\n\nyour new column is always added at the end of your tibble (data frame)\nthe value to the left of the =  is the new name for you column and could be called anything\nif you want to replace a column, the value to the left of the =  must be exactly the same name as the column to replace\n\n\n\n\nsummarise() returns a new tibble (data frame) containing summary statistics based on what has been specified in the function.\nIn the example below the summarise function has calculated the average life expectancy for the whole gapminder dataset by averaging all observations (or rows). On its own,  summarise()  is not so useful, but when combined with group_by()  its use becomes apparent, see later examples.\n\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\n  summarise(avg_life_exp = mean(lifeExp))\n\n# A tibble: 1 × 1\n  avg_life_exp\n         &lt;dbl&gt;\n1         59.5\n\n\nUseful for:\n\ncombining with group_by()  to perform grouped calculations\n\n\n\n\ngroup_by() lets you choose how you want the variables in your dataset to be grouped so that you can perform operations (such as sum() or mean()) on these groups.\nIn the example below we have grouped our data by the variable year. Notice that the output to this chunk of code looks no different to how it would look if we just ran  gapminderwithout any grouping. This is because the effects of group_by()  are only noticeable when we start performing operations.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\n  group_by(year)\n\n# A tibble: 1,704 × 6\n# Groups:   year [12]\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 1,694 more rows\n\n\nIn this next example we have combined group_by() with the summarise() command and now, instead of seeing an average life expectancy for the whole tibble (as in the example above), we see that life expectancy has been averaged within each year group.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\ngroup_by(year) %&gt;%\n  summarise(avg_life_exp = mean(lifeExp))\n\n# A tibble: 12 × 2\n    year avg_life_exp\n   &lt;int&gt;        &lt;dbl&gt;\n 1  1952         49.1\n 2  1957         51.5\n 3  1962         53.6\n 4  1967         55.7\n 5  1972         57.6\n 6  1977         59.6\n 7  1982         61.5\n 8  1987         63.2\n 9  1992         64.2\n10  1997         65.0\n11  2002         65.7\n12  2007         67.0\n\n\nUseful for:\n\ncombining with summarise()or mutate() for grouped calculations\npreparing summary statistics for plotting\nexploring values within groups in your data\n\nRemember:\n\nto use  ungroup()  if carrying out further data manipulations to avoid unexpected results, as by default, mutate() and summarise() silently retain the groupings.\nthe value to the left of the  =  is the new name for your column and could be called anything\n\nleft_join()  allows you to combine two datasets\nIn the example below we are joining the gapminder tibble to another tibble we can access directly from the gapminder package, the  country_codes data frame, in order to add the ISO country codes.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\n  left_join(country_codes)\n\nJoining with `by = join_by(country)`\n\n\n# A tibble: 1,704 × 8\n   country     continent  year lifeExp      pop gdpPercap iso_alpha iso_num\n   &lt;chr&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;int&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779. AFG             4\n 2 Afghanistan Asia       1957    30.3  9240934      821. AFG             4\n 3 Afghanistan Asia       1962    32.0 10267083      853. AFG             4\n 4 Afghanistan Asia       1967    34.0 11537966      836. AFG             4\n 5 Afghanistan Asia       1972    36.1 13079460      740. AFG             4\n 6 Afghanistan Asia       1977    38.4 14880372      786. AFG             4\n 7 Afghanistan Asia       1982    39.9 12881816      978. AFG             4\n 8 Afghanistan Asia       1987    40.8 13867957      852. AFG             4\n 9 Afghanistan Asia       1992    41.7 16317921      649. AFG             4\n10 Afghanistan Asia       1997    41.8 22227415      635. AFG             4\n# ℹ 1,694 more rows\n\n\nUseful for:\n\ncombining two sets of data which share an id (e.g. patient id, appointment id)\nadding in information from a lookup table (e.g. country codes, Health Board names)\n\nRemember:\n\nto watch out what happens to missing values\nto keep an eye on the number of observations in each tibble before and after joining\nto check which columns are being joined by\n\nOther functions for wrangling data and what they might be useful for:\n\n arrange()  for sorting the values within a column\n desc() for indicating descending sort order when used within arrange()\n str_replace()  for updating spelling mistakes in a column\n paste()  for joining things together and adding new text \n ymd()  for reading in dates in strange formats\n factor()  for converting a variable to factor data type\n fct_relevel()  for changing the order of factors\n pivot_longer()  for reshaping your data if you have values in column headings\n pivot_wider()  for reshaping your data if you have multiple variables in one column",
    "crumbs": [
      "Content",
      "Week 4: Analysing and Presenting Data in R",
      "Topic 3: Roundup and recap"
    ]
  },
  {
    "objectID": "content/week-4/topic-3.html#plotting-and-tables-recap",
    "href": "content/week-4/topic-3.html#plotting-and-tables-recap",
    "title": "Roundup and recap",
    "section": "Plotting and tables recap",
    "text": "Plotting and tables recap\nIn the examples below we provide a recap on how to use ggplot2 to build up layers on a plot. Included are examples of argument options which you might want to experiment with in your own plots. I rarely remember any of the argument specifics and always fine-tune my plots by pressing `F1` on the various functions I’m using and exploring the documentation (F1, or fn+F1 on some computers opens up the Help tab). Then it’s a process of trial and error.  \nComments are included before each new line or layer to describe what is happening.\n\nThe blank canvas\n\nlibrary(tidyverse)\nlibrary(gapminder)\n     \n    # Data we are sending to ggplot()\ngapminder %&gt;%\n    # lets create a plot\n ggplot(aes(    # specify the axes\n      x = year,\n      y = lifeExp))\n\n\n\n\n\n\n\n\nRemember:\n\nthat everything from now on needs  + at end of line instead of  %&gt;% \n\n\n\nPlot type\n\nlibrary(tidyverse)\nlibrary(gapminder)\n     \ngapminder %&gt;%\n  ggplot(aes(x = year, y = lifeExp)) +\n  # specify type of plot: scatter with jitter\n  geom_jitter(\n    # colour life expectancy based on values\n    aes(colour = lifeExp),\n    # set \"alpha\" making points same transparency\n    alpha = 0.6,\n    # specify width of \"jitter\"\n    width = 0.5)\n\n\n\n\n\n\n\n\nRemember:\n\ncolour is specified inside the  aes() function because we want it to be dependent on the values in the data\n alpha and  width are specified outside the  aes() function because we want to specify a fixed value for these arguments\n\n\n\nFaceting\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\n  ggplot(aes(x = year, y = lifeExp)) +\n  geom_jitter(aes(colour = lifeExp),\n              alpha = 0.6,\n              width = 0.5) +\n  # create muti-panle plot\n  facet_wrap(\n    # based on continent grouping\n    ~ continent)\n\n\n\n\n\n\n\n\nUseful for:\n\ncomparing values between different categories in your dataset\n\n\n\nIncluding a second geom, e.g., geom_boxplot()\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\n  ggplot(aes(x = year, y = lifeExp)) +\n  geom_jitter(aes(colour = lifeExp),\n              alpha = 0.6,\n              width = 0.5) +\n  facet_wrap(~ continent) +\n  # specify type of plot: boxplot\n  geom_boxplot(\n    # group by year (discrete) as currently \"int\" data type (continuous)\n    aes(group = year),\n    # set \"alpha\" so we can see jitter points underneath\n    alpha = 0.3,\n    # remove boxplot outliers as already present in \"jitter\" layer\n    outlier.shape = NA)\n\n\n\n\n\n\n\n\nRemember:\n\nDepending on whether your variable is stored as a “number” or a “character” or a “factor” will determine how ggplot2 deals with it\n\n\n\nStandard themes\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder %&gt;%\n  ggplot(aes(x = year, y = lifeExp)) +\n  geom_jitter(aes(colour = lifeExp),\n              alpha = 0.6,\n              width = 0.5) +\n  facet_wrap(~ continent) +\n  geom_boxplot(aes(group = year),\n               alpha = 0.3,\n               outlier.shape = NA) +\n  # choose a standard theme: dark\n  theme_dark()\n\n\n\n\n\n\n\n\nUseful for:\n\nquickly changing how your plot looks by applying one of the built in themes:  theme_bw() ,  theme_classic() ,  theme_dark() etc.",
    "crumbs": [
      "Content",
      "Week 4: Analysing and Presenting Data in R",
      "Topic 3: Roundup and recap"
    ]
  },
  {
    "objectID": "content/week-4/topic-3.html#making-tables",
    "href": "content/week-4/topic-3.html#making-tables",
    "title": "Roundup and recap",
    "section": "Making Tables",
    "text": "Making Tables\nTables are another important tool to have in your data analysis toolbox for communcating. As a general rule, when deciding between tables for graphs/plots:\n\nuse tables when the display will be used to look up individual values or you want to compare individual values \nuse graphs when the display will be used to reveal relatonships among whole sets of values or between variables \n\nTo make tables, we worked with the kable function and kableExtra package in R. \nThe general gt workflow includes 3 key steps: \n\nwrangle your data for the table by either piping %&gt;% the data or creating a new data object (tabledata &lt;- data %&gt;% mutate(...)) \npass the wrangled data to the kable function %&gt;% kable()\nformat the table object for presentation \n\n\nStep 1: Wrangle data for the table\nLets say we are interested in average life expectancy in Africa, Asia, and Oceania in the years 1952, 1972, 1992, and 2002 \n\nlibrary(tidyverse)\nlibrary(knitr)\n\nWarning: package 'knitr' was built under R version 4.2.3\n\nlibrary(kableExtra)\n\nWarning: package 'kableExtra' was built under R version 4.2.3\n\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(gapminder)\n\ntabledata &lt;- gapminder %&gt;%\ngroup_by(year, continent) %&gt;%\nsummarise(avg_life_exp = mean(lifeExp)) %&gt;% \nfilter(continent %in% c(\"Africa\", \"Asia\", \"Oceania\"),\nyear %in% c(1952, 1972, 1992, 2002))\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\n\n\n\nStep 2: Create the kable table object\n\ntabledata %&gt;% kable()\n\n\n\n\nyear\ncontinent\navg_life_exp\n\n\n\n\n1952\nAfrica\n39.13550\n\n\n1952\nAsia\n46.31439\n\n\n1952\nOceania\n69.25500\n\n\n1972\nAfrica\n47.45094\n\n\n1972\nAsia\n57.31927\n\n\n1972\nOceania\n71.91000\n\n\n1992\nAfrica\n53.62958\n\n\n1992\nAsia\n66.53721\n\n\n1992\nOceania\n76.94500\n\n\n2002\nAfrica\n53.32523\n\n\n2002\nAsia\n69.23388\n\n\n2002\nOceania\n79.74000\n\n\n\n\n\n\n\nStep 3: Format the table for presentation\nHow you decide to format and customise your table visually is a stylistic and personal choice. However, there are a few key principles to keep in mind: \n\nyou should always change the name of your variables to be meaingful to stakeholders who are not familiar with your data - that is, do not keep column names the same as they are called in your dataset \ngenerally, it is a good idea to have a title on each table \nfor reproducibility, it is a good idea to include the data source if you are using an openly available dataset \nbe consistent: use capital or lower case letters in a consistent way\nformat numbers in an interpretable way (generally speaking, you do not need to include more than 2 or 3 decimal places)\n\nBelow is one way you could format the table for presentation: \n\ntabledata %&gt;%\n  kable(col.names = c(\"Year\", \"Continent\", \"Average Life Expectancy\"),\n        align = \"clc\",\n        digits = 2,\n        caption = \"Life Expectancy in Africa, Asia, and Oceania: Data from 1952, 1972, 1992, and 2002\") %&gt;%\n  kable_styling(\"striped\", full_width = FALSE) %&gt;%\n  footnote(general = \"Data from the gapminder dataset\")\n\n\nLife Expectancy in Africa, Asia, and Oceania: Data from 1952, 1972, 1992, and 2002\n\n\nYear\nContinent\nAverage Life Expectancy\n\n\n\n\n1952\nAfrica\n39.14\n\n\n1952\nAsia\n46.31\n\n\n1952\nOceania\n69.25\n\n\n1972\nAfrica\n47.45\n\n\n1972\nAsia\n57.32\n\n\n1972\nOceania\n71.91\n\n\n1992\nAfrica\n53.63\n\n\n1992\nAsia\n66.54\n\n\n1992\nOceania\n76.94\n\n\n2002\nAfrica\n53.33\n\n\n2002\nAsia\n69.23\n\n\n2002\nOceania\n79.74\n\n\n\nNote: \n\n\n\n\n Data from the gapminder dataset",
    "crumbs": [
      "Content",
      "Week 4: Analysing and Presenting Data in R",
      "Topic 3: Roundup and recap"
    ]
  },
  {
    "objectID": "content/week-4/topic-3.html#combined-example",
    "href": "content/week-4/topic-3.html#combined-example",
    "title": "Roundup and recap",
    "section": "Combined Example",
    "text": "Combined Example\nIn the example below you can see a simple R Markdown document without any narrative text added yet, just the YAML then a series of code chunks outlining the various stages in the data analysis process.\nCODE IS HERE!!\nWhich when knitted to a pdf document looks like this:\nPDF IS HERE!\nThe next step would be to add in narrative text, creating a comprehensive analysis.",
    "crumbs": [
      "Content",
      "Week 4: Analysing and Presenting Data in R",
      "Topic 3: Roundup and recap"
    ]
  },
  {
    "objectID": "content/week-4/topic-3.html#optional-data-engagement-data-controversies",
    "href": "content/week-4/topic-3.html#optional-data-engagement-data-controversies",
    "title": "Roundup and recap",
    "section": "Optional: Data Engagement & Data Controversies",
    "text": "Optional: Data Engagement & Data Controversies\nCritically review the arguments posed in this article:\nMittelstadt B (2019) Principles alone cannot guarantee ethical AI. Nat Mach Intell 1, 501–507.",
    "crumbs": [
      "Content",
      "Week 4: Analysing and Presenting Data in R",
      "Topic 3: Roundup and recap"
    ]
  },
  {
    "objectID": "content/week-5/topic-2.html",
    "href": "content/week-5/topic-2.html",
    "title": "Creating more exciting tables",
    "section": "",
    "text": "There are many packages which can be used to create tables in R. We have already looked at knitr::kable() and KableExtra in the course. Another popular table package is flextable, which is particularly powerful for making tables in Word. If you are interested, you can find a nice overview of packages for tables in R here.\ngt is the table compliment to the ggplot2 package for making plots - the first g in both cases meaning “grammar”. gt meaning “grammar of tables” and the gg in ggplot2 meaning “grammar of graphics”. This underlying general philosophy of tables makes the gt package easy to use (with some practice) and extremely flexible and customisable.\nJust as we build our plots in ggplot2 with layers, we can build gt tables by editing each part or layer of the table. As the gt developers outline: “The gt philosophy: we can construct a wide variety of useful tables with a cohesive set of table parts. These include the table header, the stub, the column labels and spanner column labels, the table body, and the table footer.”\n\n\n\nParts of a gt table\n\n\nThe gt package webpages have an excellent introduction to greating gt Tables, which you can find here.\nThomas Mock has some excellent resources on his blog as well which you may find helpful in getting accustomed to the gt package and its wide-ranging functionalities: gt cookbook as well as the advanced gt cookbook and more advanced making beautiful tables with gtExtra.\nNote: You are not expected to master gt nor the advanced elements of gt for this course. If you are interested, some advanced resources are included here. The gt introduction and gt cookbook would are a good place to start if you wish to explore the package and creating tables over and above what is covered in this optional Topic.",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 2: Creating more exciting tables"
    ]
  },
  {
    "objectID": "content/week-5/topic-2.html#the-gt-package",
    "href": "content/week-5/topic-2.html#the-gt-package",
    "title": "Creating more exciting tables",
    "section": "",
    "text": "There are many packages which can be used to create tables in R. We have already looked at knitr::kable() and KableExtra in the course. Another popular table package is flextable, which is particularly powerful for making tables in Word. If you are interested, you can find a nice overview of packages for tables in R here.\ngt is the table compliment to the ggplot2 package for making plots - the first g in both cases meaning “grammar”. gt meaning “grammar of tables” and the gg in ggplot2 meaning “grammar of graphics”. This underlying general philosophy of tables makes the gt package easy to use (with some practice) and extremely flexible and customisable.\nJust as we build our plots in ggplot2 with layers, we can build gt tables by editing each part or layer of the table. As the gt developers outline: “The gt philosophy: we can construct a wide variety of useful tables with a cohesive set of table parts. These include the table header, the stub, the column labels and spanner column labels, the table body, and the table footer.”\n\n\n\nParts of a gt table\n\n\nThe gt package webpages have an excellent introduction to greating gt Tables, which you can find here.\nThomas Mock has some excellent resources on his blog as well which you may find helpful in getting accustomed to the gt package and its wide-ranging functionalities: gt cookbook as well as the advanced gt cookbook and more advanced making beautiful tables with gtExtra.\nNote: You are not expected to master gt nor the advanced elements of gt for this course. If you are interested, some advanced resources are included here. The gt introduction and gt cookbook would are a good place to start if you wish to explore the package and creating tables over and above what is covered in this optional Topic.",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 2: Creating more exciting tables"
    ]
  },
  {
    "objectID": "content/week-5/topic-2.html#the-gt-table-workflow",
    "href": "content/week-5/topic-2.html#the-gt-table-workflow",
    "title": "Creating more exciting tables",
    "section": "The gt table workflow",
    "text": "The gt table workflow\nNot only is gt like ggplot2 but for tables, but it also follows tidyverse conventions! This means you can pipe your wrangled data into the gt() function seemlessly.\nA typical gt Table workflow is visualized below:\n\n\n\n\n\nYou begin with a preprocessed tabular data, such as a tibble. Next you create your gt table and customize it to your needs. Finally, the table is rendered by printing it at the console, including it in an R Markdown document, or exporting to a file using the gtsave() function.\nThe code can look a bit scary, but do not fear! Think about it as writing down in code all of the edits that you would make to a table in Word - only now it is reproducible as you have written this in code!",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 2: Creating more exciting tables"
    ]
  },
  {
    "objectID": "content/week-5/topic-2.html#an-example-of-gt-workflow",
    "href": "content/week-5/topic-2.html#an-example-of-gt-workflow",
    "title": "Creating more exciting tables",
    "section": "An example of gt workflow",
    "text": "An example of gt workflow\n\nThe data\nAs with everything we have learned about in programming in this course, we must first start with the data.\nWe will be using a new dataset from Public Health Scotland:\n\nStroke Mortality by Health Board\n\nLet’s start out with some data wrangling to get the data ready for presentation in a table\n\n# load libraries \n library(tidyverse)  \n library(gt) # remember to install gt in the first instance with install.packages(\"gt\")\n \n # import data\n stroke_mortality_raw &lt;- read_csv(\"https://www.opendata.nhs.scot/dataset/f5dcf382-e6ca-49f6-b807-4f9cc29555bc/resource/19c01b59-6cf7-42a9-876a-b07b9b92d6eb/download/stroke_mortalitybyhbr.csv\")\n \n hb &lt;- read_csv(\"https://www.opendata.nhs.scot/dataset/9f942fdb-e59e-44f5-b534-d6e17229cc7b/resource/652ff726-e676-4a20-abda-435b98dd7bdc/download/hb14_hb19.csv\")\n \n stroke_mortality &lt;- stroke_mortality_raw %&gt;%\n # Join cancelled to hb\n   left_join(hb, by = c(\"HBR\" = \"HB\")) %&gt;%\n # select the variables we are interested in \n   select(Year, HBName, AgeGroup, Sex, Diagnosis, NumberOfDeaths, CrudeRate, EASR) %&gt;% \n # filter out aggregate levels of the variables \n   filter(Sex != \"All\" & AgeGroup != \"All\")",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 2: Creating more exciting tables"
    ]
  },
  {
    "objectID": "content/week-5/topic-2.html#create-a-gt-table-with-gt",
    "href": "content/week-5/topic-2.html#create-a-gt-table-with-gt",
    "title": "Creating more exciting tables",
    "section": "Create a gt table with gt()",
    "text": "Create a gt table with gt()\nFor sake of simplicity, let’s say that we are specifically interested in the year 2020, adults 75 years old or older, and in 2 Health Boards: NHS Borders and NHS Fife.\nTo create a gt table object, all you need to do is pass your dataset, plus any data wrangling, to the gt() function. Because the gt package follows tidyverse conventions, our good friend the pipe (%&gt;%) will continue to be useful to us here to use the gt functions to modify the gt table object!\n\nstroke_mortality %&gt;%\n   filter(Year == 2020,\n          AgeGroup == \"75plus years\",\n          HBName %in% c(\"NHS Borders\", \"NHS Fife\")) %&gt;% \n   gt()\n\n\n\n\n\n\nBecause we have filtered the data to only be for one Year and one AgeGroup, it is not necessarily relevant to include them in the table as we can highlight what data is presented in the table title (covered later in this tutorial). In this case, you can first select only the variables you are interested in showing in the table before creating the gt object.\n\nstroke_mortality %&gt;%\n   filter(Year == 2020,\n          AgeGroup == \"75plus years\",\n          HBName %in% c(\"NHS Borders\", \"NHS Fife\")) %&gt;% \n   select(HBName, \n          Sex, \n          Diagnosis, \n          NumberOfDeaths, \n          CrudeRate, \n          EASR) %&gt;% \n   gt()",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 2: Creating more exciting tables"
    ]
  },
  {
    "objectID": "content/week-5/topic-2.html#modify-columns-with-the-cols_-functions",
    "href": "content/week-5/topic-2.html#modify-columns-with-the-cols_-functions",
    "title": "Creating more exciting tables",
    "section": "Modify columns with the cols_*() functions",
    "text": "Modify columns with the cols_*() functions\nColumn labels, cell alignment, column width, and placement as well as combine multiple columns with the range of cols_*() functions.\nFor example, cols_label() is particularly useful to rename columns to more informative names than what the variable is called in the dataset. This changes the labels of the columns, as per the function name, not the underlying column names (which remain the name of the variable in your dataset). Tables should be able to be understood by people who are not familiar with your dataset, so it is important for your variables to have informative names.\n\nstroke_mortality %&gt;%\n   filter(Year == 2020,\n          AgeGroup == \"75plus years\",\n          HBName %in% c(\"NHS Borders\", \"NHS Fife\")) %&gt;% \n   select(HBName, \n          Sex, \n          Diagnosis, \n          NumberOfDeaths, \n          CrudeRate, \n          EASR) %&gt;% \n   gt() %&gt;% \n   cols_label(HBName = \"Health Board\",\n              NumberOfDeaths = \"Number of Deaths\",\n              CrudeRate = \"Crude Rate\", \n              EASR = \"European Age-Sex Standardised Rate\") \n\n\n\n\n\n\ncols_align() aligns all text within a column. You can specify which columns to align using vars() - notice that the arguments are the original variable names. Commonly, the convention is to left-align text with varying length and right-align numbers. You can align different columns different ways by adding multiple cols_align() layers.\n\nstroke_mortality %&gt;%\n   filter(Year == 2020,\n          AgeGroup == \"75plus years\",\n          HBName %in% c(\"NHS Borders\", \"NHS Fife\")) %&gt;% \n   select(HBName, \n          Sex, \n          Diagnosis,\n          NumberOfDeaths,\n          CrudeRate, \n          EASR) %&gt;% \n   gt() %&gt;% \n   cols_label(HBName = \"Health Board\",\n              NumberOfDeaths = \"Number of Deaths\",\n              CrudeRate = \"Crude Rate\", \n              EASR = \"European Age-Sex Standardised Rate\") %&gt;% \n   cols_align(align = \"center\",\n              columns = NumberOfDeaths)\n\n\n\n\n\n\ncols_move_*() set of functions allows you to move columns to the start or end (or wherever you want!) in your table. To move a column to the start we use cols_move_to_start() and to move a column to the end, the function is cols_move_to_end().\n\nstroke_mortality %&gt;%\n  filter(Year == 2020,\n         AgeGroup == \"75plus years\",\n         HBName %in% c(\"NHS Borders\", \"NHS Fife\")) %&gt;% \n  select(HBName, \n         Sex, \n         Diagnosis, \n         NumberOfDeaths, \n         CrudeRate, \n         EASR) %&gt;% \n  gt() %&gt;% \n# to move the diagnosis and Sex columns to the start \n  cols_move_to_start(columns = c(Diagnosis, Sex)) %&gt;% \n# to move the HBName after Number of Deaths \n  cols_move(columns = HBName, after = NumberOfDeaths) %&gt;% \n  cols_label(HBName = \"Health Board\",\n             NumberOfDeaths = \"Number of Deaths\",\n             CrudeRate = \"Crude Rate\", \n             EASR = \"European Age-Sex Standardised Rate\") %&gt;% \n cols_align(align = \"center\", columns = NumberOfDeaths)",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 2: Creating more exciting tables"
    ]
  },
  {
    "objectID": "content/week-5/topic-2.html#format-columns-with-the-fmt_-functions",
    "href": "content/week-5/topic-2.html#format-columns-with-the-fmt_-functions",
    "title": "Creating more exciting tables",
    "section": "Format columns with the fmt_*() functions",
    "text": "Format columns with the fmt_*() functions",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 2: Creating more exciting tables"
    ]
  },
  {
    "objectID": "content/week-5/topic-2.html#and-now-to-the-stub-or-rows",
    "href": "content/week-5/topic-2.html#and-now-to-the-stub-or-rows",
    "title": "Creating more exciting tables",
    "section": "…and now to the stub (or rows)!",
    "text": "…and now to the stub (or rows)!",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 2: Creating more exciting tables"
    ]
  },
  {
    "objectID": "content/week-5/topic-2.html#add-the-final-touches",
    "href": "content/week-5/topic-2.html#add-the-final-touches",
    "title": "Creating more exciting tables",
    "section": "Add the final touches",
    "text": "Add the final touches",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 2: Creating more exciting tables"
    ]
  },
  {
    "objectID": "content/week-5/topic-2.html#bonus---introduction-video-from-gt-package-developers",
    "href": "content/week-5/topic-2.html#bonus---introduction-video-from-gt-package-developers",
    "title": "Creating more exciting tables",
    "section": "Bonus - Introduction video from gt package developers",
    "text": "Bonus - Introduction video from gt package developers",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 2: Creating more exciting tables"
    ]
  },
  {
    "objectID": "content/week-5/index.html",
    "href": "content/week-5/index.html",
    "title": "Overview",
    "section": "",
    "text": "This week you will learn about geospatial analysis and creating more exciting tables.\nThere is also optional material on writing functions",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Overview"
    ]
  },
  {
    "objectID": "content/week-5/index.html#learning-outcomes",
    "href": "content/week-5/index.html#learning-outcomes",
    "title": "Overview",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of the week you will be able to:\n\nKnow how to analyse geospatial data in R.\nUse the sf package and ggplot to plot data in a map.\nUse the gt package to creating more exciting tables.\n\n\nStructure of this week’s materials\n\nTopic 1: Introduction to Geospatial Data in R with sf and ggplot: 2 readings including practicals and code samples.\nTopic 2: Creating more exciting tables: 7 readings with code samples. 1 optional video.\nOPTIONAL: Writing and applying functions and a functions quiz.",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Overview"
    ]
  },
  {
    "objectID": "content/week-5/topic-1.html",
    "href": "content/week-5/topic-1.html",
    "title": "Introduction to Geospatial Data in R with sf and Tidyverse",
    "section": "",
    "text": "Geospatial data is data about locations and features on Earth but we often refer to geospatial data simply as “spatial data”. These data can often have latitude and longitude attached to them. An example of spatial data would be using a bus app, and you can see the location of the bus.\nAnalysing this data is referred to as spatial analysis.\nFor example, you could have a map with data layered on top:\n\n\n\ncovid_vaccine_country_Africa\n\n\nMap of share of people who received at least one dose of COVID-19 vaccine by country in Africa, 2021.svg” by Our World In Data is licensed under CC BY 4.0\n\n\n\n\n\n“Georgia Population Density by Census Tract” by Wikimedia, used under CC BY-SA 4.0\n\n\n\n\n\nOr in this example - Mountain trails in Dovrefjell National Park, Norway created by our colleague John Wilson.\n\n\n\nSpatial analysis can be used in many disciplines to aid decision makers in their decision making process. Urban planners might use it as might logistics practitioners.\nIn the health context, vaccination strategies can be informed or the tracking of infectious diseases can be greatly improved.\nOne famous example is John Snow’s investigation into a cholera outbreak in London in 1854. Not convinced that the disease was transmitted by air but rather through the water system, he plotted points on a map to show that cholera deaths were clustered around water outlets.\nRead more on BBC Bitesize\n\n\n\nJohn Snow’s Cholera Map 1854 (public domain)",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 1: Introduction to Geospatial Data in R with sf and Tidyverse"
    ]
  },
  {
    "objectID": "content/week-5/topic-1.html#spatial-analysis",
    "href": "content/week-5/topic-1.html#spatial-analysis",
    "title": "Introduction to Geospatial Data in R with sf and Tidyverse",
    "section": "",
    "text": "Geospatial data is data about locations and features on Earth but we often refer to geospatial data simply as “spatial data”. These data can often have latitude and longitude attached to them. An example of spatial data would be using a bus app, and you can see the location of the bus.\nAnalysing this data is referred to as spatial analysis.\nFor example, you could have a map with data layered on top:\n\n\n\ncovid_vaccine_country_Africa\n\n\nMap of share of people who received at least one dose of COVID-19 vaccine by country in Africa, 2021.svg” by Our World In Data is licensed under CC BY 4.0\n\n\n\n\n\n“Georgia Population Density by Census Tract” by Wikimedia, used under CC BY-SA 4.0\n\n\n\n\n\nOr in this example - Mountain trails in Dovrefjell National Park, Norway created by our colleague John Wilson.",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 1: Introduction to Geospatial Data in R with sf and Tidyverse"
    ]
  },
  {
    "objectID": "content/week-5/topic-1.html#why-is-it-important",
    "href": "content/week-5/topic-1.html#why-is-it-important",
    "title": "Introduction to Geospatial Data in R with sf and Tidyverse",
    "section": "",
    "text": "Spatial analysis can be used in many disciplines to aid decision makers in their decision making process. Urban planners might use it as might logistics practitioners.\nIn the health context, vaccination strategies can be informed or the tracking of infectious diseases can be greatly improved.\nOne famous example is John Snow’s investigation into a cholera outbreak in London in 1854. Not convinced that the disease was transmitted by air but rather through the water system, he plotted points on a map to show that cholera deaths were clustered around water outlets.\nRead more on BBC Bitesize\n\n\n\nJohn Snow’s Cholera Map 1854 (public domain)",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 1: Introduction to Geospatial Data in R with sf and Tidyverse"
    ]
  },
  {
    "objectID": "content/week-5/topic-1.html#wait-whats-vector-data",
    "href": "content/week-5/topic-1.html#wait-whats-vector-data",
    "title": "Introduction to Geospatial Data in R with sf and Tidyverse",
    "section": "Wait, what’s vector data?",
    "text": "Wait, what’s vector data?\nVector data is data that represents features in the world as either points, lines or polygons.\n\nPoints: A single pair of coordinates. For example the x,y position of a tower location.\nLines: Two or more connected points. For example, the start and end of a pathway.\nPolygons: Three or more points that are connected and closed. For example, the outline of a loch.\n\n\n\n\n\n\nNational Ecological Observatory Network.",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 1: Introduction to Geospatial Data in R with sf and Tidyverse"
    ]
  },
  {
    "objectID": "content/week-5/topic-1.html#shapefiles",
    "href": "content/week-5/topic-1.html#shapefiles",
    "title": "Introduction to Geospatial Data in R with sf and Tidyverse",
    "section": "Shapefiles",
    "text": "Shapefiles\nThe most common file format for vector data is a Shapefile which has the extension .shp. It stores the points, lines or polygons of the dataset. .shp files can store only one type: points, lines or polygons and comes with metadata which indicates which type it stores. Working with Shapefiles in R can be a bit more challenging than working with normal data frames and tibbles, but they allow you to have rich datasets with geographic content.\n\nFurther resources:\nFor more about vector data see Introduction to Vector Data (Data Carpentry)",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 1: Introduction to Geospatial Data in R with sf and Tidyverse"
    ]
  },
  {
    "objectID": "content/week-5/topic-1.html#simple-spatial-features-sf",
    "href": "content/week-5/topic-1.html#simple-spatial-features-sf",
    "title": "Introduction to Geospatial Data in R with sf and Tidyverse",
    "section": "Simple spatial features (sf)",
    "text": "Simple spatial features (sf)\nsf stands for Simple Features, a standardized format for representing spatial vector data. It follows a formal standard that defines how spatial geometries—such as points, lines, and polygons—are stored and accessed.\nBut what exactly is a feature? You can think of a feature as an object. In the real world, objects can be anything: a building, a tree, or a satellite. While we refer to them as single ‘objects’, they actually consist of various components. For instance, a tree is made up of a trunk, branches, and leaves. A feature follows the same concept: it may represent a single entity but can consist of multiple parts, along with attributes that describe it.\n“Simple Features (officially Simple Feature Access) is a set of standards that specify a common storage and access model of geographic features made of mostly two-dimensional geometries (point, line, polygon, multi-point, multi-line, etc.) used by geographic databases and geographic information systems. It is formalized by both the Open Geospatial Consortium (OGC) and the International Organization for Standardization (ISO).” - Wikipedia\nThe following seven simple feature types are the most common:\n\n\n\n\n\nIn the sf package, spatial objects are stored as a simple data frame with a special column that holds the geometry coordinates. This special column is a list, with each element corresponding to a row in the data frame. The length of each list element varies, depending on how many coordinates are needed to represent each individual feature. To work with sf objects in R, we use the sf package.\n\nNew Zealand Census Example\nLet’s look at an example. Download and unzip the file below into a “data” folder and create an RProject and a new RMarkdown file (new_zealand_census.Rmd). This data is aggregated census data from New Zealand from 2013.\nOr you can download the completed example complete-new-zealand-census2013.zip\nYou’ll notice there are 4 files. This is the format of Esri Shapefiles. (Esri is a geographic science and geospatial analytics company).\n\n.shp: The main file that contains the feature geometry\n.shx: The index file that stores the index of the feature geometry\n.dbf: The dBASE table that stores the attribute information of features\n.prj: A text file that contains information about a coordinate system and map projection\n\nThe .shp file is our spatial data and is already an sf object (the other files are part of the specification and are used to make reading the data more efficient).This means we can read the file in using the st_read() function to read it into our code. All of the functions in the sf package that operate on spatial data start with “st_”. This stands for spatial and temporal.\nLet’s load the data and have a look.\n\n# You may need to install.packages(\"sf\")\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(here) \nlibrary(janitor) # This is for cleaning the variable names\n\n\n# Read in data about New Zealand using the st_read function\nnz_census2013 &lt;- st_read(here(\"data\" ,\"nz_census2013.shp\"))\n \n# We'll use clean_names from janitor package to quickly clean up messy column names.\n# It changes them all to lowercase and adds \"_\" for spaces\nnz_census2013 &lt;- nz_census2013 %&gt;% \n  clean_names()\n\nClick on the nz_census2013 object. Here we can see:\n\nsimple features object (sf): a single observation.\nsimple feature geometry list-column (sfc) : this is the geometry column.\nsimple feature geometry (sfg) : this is the values within the geometry column. We can see the type is MULTIPOLYGON.\n\n\n\n\n\n\nWhen you inspect the data, you’ll see that the geometries are placed in a list-column. Each element of this list holds the simple feature geometry for a particular feature, as geometries are not single-valued.\n\n# check class and look at the data\nclass(nz_census2013)\n\nWhen we check the class of the nz_census2013 object we can see that it is both a data.frame and an sf object.\nWe can access the geometry aspect of your spatial data by calling the st_geometry function:\n\nnz_geometry &lt;- st_geometry(nz_census2013)\nnz_geometry\n\nWe can see that the geometry column is a list of polygons made up of points.",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 1: Introduction to Geospatial Data in R with sf and Tidyverse"
    ]
  },
  {
    "objectID": "content/week-5/topic-1.html#plotting-the-data",
    "href": "content/week-5/topic-1.html#plotting-the-data",
    "title": "Introduction to Geospatial Data in R with sf and Tidyverse",
    "section": "Plotting the data",
    "text": "Plotting the data\nFor visualisation, the sf package extends the base plot command, so it can be used on sf objects. If used without any arguments it will plot all the attributes.\n\n# If you want to plot all variables, you can do the following:\nplot(nz_census2013)\n\n\n\n\n\n\n\n# Or we could plot only the area variable of the sf object.\n# Because it's an sf object we can't use the $ operator to get the results we want (e.g. nz_census2013$area). \n# Instead, we use the square bracket notation.\nplot(nz_census2013[\"area\"])\n\n\n\n\n\n\nThis is great but often we’ll want to use ggplot because it gives us more control over our plots.\n\nPlotting spatial data with ggplot\nLuckily, there is a function built into ggplot called geom_sf. Let’s try it.\n\n# plot the data using ggplot \nggplot(data = nz_census2013, aes(fill = pop)) + \n  geom_sf() +\n  scale_fill_continuous(labels = scales::label_comma())\n\n\n\n\n\n\nMuch better! Here are a few more examples:\n\nggplot(data = nz_census2013, aes(fill = income)) + \n  # colour and linewidth refer to the outline of the map\n  geom_sf(colour = \"white\", linewidth = 0.1) +\n  scale_fill_viridis_c(name = \"Income in $\") +\n  theme_void() +\n  labs(title = \"Average Income by Region 2013\")\n\n\n\n\n\n\nLet’s say we wanted to display a map illustrating the average region percentage of each island who are Maori:\n\n# Group by island and summarise to get mean of maori per region\nnz_census_summary_by_island &lt;- nz_census2013 %&gt;% \n  group_by(island) %&gt;% \n  summarise(average_percent_maori = mean(maori))\n \n \n# Extract the North Island's average percentage Maori for the subtitle\n# We use pull() to get just the values from a specific column, rather than returning a tibble\nnorth_island_percent &lt;- nz_census_summary_by_island %&gt;%\n  filter(island == \"North\") %&gt;%\n  pull(average_percent_maori)\n \n \n# Extract the South Island's average percentage Maori for the subtitle\nsouth_island_percent &lt;- nz_census_summary_by_island %&gt;%\n  filter(island == \"South\") %&gt;%\n  pull(average_percent_maori)\n \n \nnz_census_summary_by_island  %&gt;% \n  ggplot(aes(fill = average_percent_maori)) +\n  geom_sf(colour = \"black\", linewidth = 0.5) +\n  scale_fill_viridis_c(\n    name = \"Percent\",\n    labels = function(x) x * 100\n ) +\n  theme_void() +\n  labs(\n    title =\"Average Region Percentage of Population Maori 2013\",\n    subtitle = paste0(\"North Island: \", round(north_island_percent * 100, 1), \", South Island: \", round(south_island_percent * 100, 1))\n  ) \n\n\n\n\n\n\nThinking point: Why there are only two colours on the map?\n\n\nKey Takeaways\n\nSpatial data is represented by “vector” data, including points, lines, and polygons.\nPoints: Single coordinates (e.g., a tower location).\nLines: Connected points (e.g., pathways).\nPolygons: Closed shapes formed by points (e.g., boundaries of a loch).\nShapefiles are a common file format for vector data, storing geographical features (points, lines, polygons).\nShapefiles include multiple files (.shp, .shx, .dbf, .prj) that contain feature geometry and attribute information.\nThe sf package in R is used to work with spatial vector data.\nSpatial data is stored in a data frame with a special geometry column, and functions for spatial operations start with “st_”.\nThe st_read() function is used to read shapefiles into R as sf objects.\nVisualization: Plot sf data using ggplot2 with geom_sf() for better customization.",
    "crumbs": [
      "Content",
      "Week 5: Making Maps and Tables in R",
      "Topic 1: Introduction to Geospatial Data in R with sf and Tidyverse"
    ]
  }
]